{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searchTerm='#trump'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Enter the search term here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(twitteR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(sqldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(ggmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "consumer_key <- ''\n",
    "consumer_secret <- ''\n",
    "access_token <- ''\n",
    "access_secret <- ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Set up twitter OAuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db <- dbConnect(SQLite(), dbname='dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "register_db_backend(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Creates a database file named 'dic'. It is included in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = searchTwitter(searchTerm,n=100)\n",
    "store_tweets_db(tweets)\n",
    "\n",
    "data = twListToDF(tweets)\n",
    "min = data[which.min(data$id),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//The above code searches twitter for 100 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxid = as.numeric(min[[8]])-100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//The above code finds the minimum id of the above batch so that it acts as the maxid for the next batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while(count!=150){\n",
    "    tweets = searchTwitter(searchTerm,n=100, maxID=maxid)\n",
    "    store_tweets_db(tweets)\n",
    "    data = twListToDF(tweets)\n",
    "    min = data[which.min(data$id),]\n",
    "    maxid = as.numeric(min[[8]])-100\n",
    "    count=count+1\n",
    "    print(count)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//The above code seaches twitter for 100 tweets, 150 times and storing the tweets in the database at the same time. Total of 15000 tweets. \n",
    "//Due to API limits the total is kept 15000. It can be increased or the loop can be run over again as per convinience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from_db = load_tweets_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = twListToDF(from_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "screenname = data[['screenName']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Above lines of code load the tweets from the database and convert them to Dataframe. Then get the screen name of each tweet from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i=1\n",
    "user=''\n",
    "while(i<20000)\n",
    "    {\n",
    "    user = c(user,screenname[i])\n",
    "    i=i+1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Above code makes user variable containing all the screen names to pass it on to the next function at a time. i.e. lookUpUsers() to get the info on the user having the screen name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user1 = lookupUsers(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user2 = twListToDF(user1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user4 = user2[!user2$location == '', ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Above code deletes all the users having nothing as location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat(user4$location,file='/Users/anandpopat/desktop/b.csv',sep='\\n',append=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Above code writes the data to file to save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "address<-readLines('/Users/anandpopat/desktop/b.csv', n = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Reads the data saved in the above line to the file. Can be skipped but just to keep a backup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_reply=''\n",
    "geo_reply<-as.numeric(geocode(address[i]))\n",
    "df3=data.frame(geo_reply[1],geo_reply[2])\n",
    "i=i+1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while(i<500){\n",
    "    geo_reply=''\n",
    "    geo_reply<-as.numeric(geocode(address[i]))\n",
    "    df1=data.frame(geo_reply[1],geo_reply[2])\n",
    "    df3=rbind(df3,df1)\n",
    "    i=i+1\n",
    "    print(i)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Above lines of code get the geocode which is a google API function to get the lat-lon pair of location of the users we collected in the previous steps. \n",
    "//Due to API limits and other errors the batch processing is done in the size of 500s. Can be increased as per convinience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write.csv(file='/Users/anandpopat/desktop/location1.csv',x=df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read=read.csv('/Users/anandpopat/desktop/location1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//The data is written and read from 9 location files which are included in the folder. Each file has 500 locations except location2.csv which has 1000 locations. The path has to be changed for each file. Again the processing is done in batches of 500s. To avoid writing data to different files, the limit can be increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Data written to file and read again just for backup purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "j=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while(j<500){\n",
    "    \n",
    "    loc = as.numeric(read[j,2:3])\n",
    "    state=revgeocode(loc,output ='more')\n",
    "    state1=toString(state$administrative_area_level_1)\n",
    "    if(toString(state$country)=='United States')\n",
    "    {\n",
    "        if(state1!=\"\")\n",
    "        {\n",
    "            cat(state1,file='/Users/anandpopat/desktop/state1.csv',sep='\\n',append=TRUE)\n",
    "        }\n",
    "    }\n",
    "    j=j+1\n",
    "    print(j)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Above lines of code reverse geocode the lat-lon pair obtained in the previous steps to get a concrete address and then filter out any address not in US. Only the states obtained from the results are saved and written to a file for backup purposes.\n",
    "//Again due to API limits the batch is processed in 500s. Can be increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2421 geocoding queries remaining.\n"
     ]
    }
   ],
   "source": [
    "geocodeQueryCheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Just to check how many API calls still left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "read_state<-readLines('/Users/anandpopat/desktop/state1.csv', n = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "read_state=data.frame(read_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Reads the states we saved in the previous step and convert it to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grp1 <- group_by(read_state,read_state)\n",
    "(grp2 <- summarize(grp1,count=n()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Above code groups the states and gives the count of its occurence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write.csv(file='/Users/anandpopat/desktop/final_list1.csv',x=grp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Saves the states with their count of occurence in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_list1 = read.csv(\"/Users/anandpopat/desktop/final_list1.csv\")\n",
    "final_list1$read_state <- as.character(final_list1$read_state)\n",
    "final_list1$count = as.numeric(final_list1$count)\n",
    "final_list1 = final_list1[final_list1$read_state != \"Alaska\", ]\n",
    "final_list1 = final_list1[final_list1$read_state != \"Hawaii\", ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Makes a proper data frame for further processing from the data saved in the previous step. Also removes alaska and hawaii from the result to obtain a 'united' united states map. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (i in 1:nrow(final_list1)) {\n",
    "  latlon = geocode(final_list1[i,2])\n",
    "  final_list1$lon[i] = as.numeric(latlon[1])\n",
    "  final_list1$lat[i] = as.numeric(latlon[2])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Above lines of code get the lat-lon pair of the states of US obtained in the previous step for plotting on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write.csv(file='/Users/anandpopat/desktop/final_list_loc1.csv',x=final_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_list1=read.csv(file='/Users/anandpopat/desktop/final_list_loc1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_count = data.frame(final_list1$count, final_list1$lon, final_list1$lat)\n",
    "colnames(state_count) = c('count','lon','lat')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Set a proper data frame from the data saved in the file i.e count, state, lat and lon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usa = as.numeric(geocode(\"United States\"))\n",
    "mymap = ggmap(get_googlemap(center=usa, scale=2, zoom=4), extent=\"normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Get the map of USA from ggmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mymap + geom_point(aes(x=final_list1$lon, y=final_list1$lat), data=state_count, col=\"orange\", alpha=0.4, size=state_count$count*0.1) + scale_size_continuous(range=range(state_read$count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Add orange blobs to the map of USA showing the density of the tweets coming from that area.\n",
    "//State count in multiplied by 0.1 to adjust the size of the blob. Can be changed to suit the needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "REFERENCES:\n",
    "DIC Lab1.pdf\n",
    "twitteR Vignette.\n",
    "https://blog.dominodatalab.com/geographic-visualization-with-rs-ggmaps/\n",
    "https://www.r-bloggers.com/mapping-twitter-followers-in-r/\n",
    "https://www.r-bloggers.com/dplyr-example-1/"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
